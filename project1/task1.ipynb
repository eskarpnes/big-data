{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"Notebook.ipynb\")\n",
    "albums = os.path.join(os.getcwd(), \"project1/data\", \"albums.csv\")\n",
    "artists = os.path.join(os.getcwd(), \"project1/data\", \"artists.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"Big D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "albums_raw = sc.textFile(albums)  # one list with all the data\n",
    "albums_rdd = albums_raw.map(lambda x: x.split(','))  # proper csv format (list of lists)\n",
    "\n",
    "artists_raw = sc.textFile(artists)\n",
    "artists_rdd = artists_raw.map(lambda x: x.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'artist_id', 'album_title', 'genre', 'year_of_pub', 'num_of_tracks', 'num_of_sales', 'rolling_stone_critic', 'mtv_critic', 'music_maniac_critic']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "fields = 'id artist_id album_title genre year_of_pub num_of_tracks num_of_sales rolling_stone_critic mtv_critic music_maniac_critic'.split()\n",
    "print fields\n",
    "def task_1():\n",
    "    print albums_rdd.map(lambda x: x[3]).distinct().count()\n",
    "task_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n 'real_name',\n 'art_name',\n 'role',\n 'year_of_birth',\n 'country',\n 'city',\n 'email',\n 'zip_code']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_fields = 'id real_name art_name role year_of_birth country city email zip_code'.split()\n",
    "artists_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1955\n"
     ]
    }
   ],
   "source": [
    "def task_2():\n",
    "    print artists_rdd.sortBy(lambda x: x[4]).first()[4]\n",
    "task_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_column_val(rdd, col):\n",
    "    return rdd.map(lambda x: x[col]).countByValue()\n",
    "\n",
    "def sort_key_val(data, key_is_num=False):\n",
    "    sort = lambda(k,v): (-v, k)\n",
    "    if key_is_num:\n",
    "        # make sure we sort by int value and not str\n",
    "        # e.g \"764\">\"6082\"\n",
    "        sort = lambda(k,v): (-v, int(k))\n",
    "    return [x for x in sorted(data.items(), key=sort)]\n",
    "\n",
    "def rdd(data):\n",
    "    return sc.parallelize(data)\n",
    "\n",
    "def delimit(*args):\n",
    "    parsed = []\n",
    "    for arg in args:\n",
    "        tmp = arg\n",
    "        if type(arg) == int or type(arg) == float:\n",
    "            tmp = str(arg)\n",
    "        elif type(arg) != str:\n",
    "            tmp = arg.encode('utf-8')\n",
    "        parsed.append(tmp)       \n",
    "    return '\\t'.join(parsed)\n",
    "\n",
    "def save_as_tsv(data, filename):\n",
    "    as_rdd = rdd(data)\n",
    "    delimited = as_rdd.map(lambda (k,v): delimit(k, v))\n",
    "    delimited.saveAsTextFile(os.path.join(os.getcwd(), filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_3():\n",
    "    COL_COUNTRY = 5\n",
    "    sorted_by_country = sort_key_val(count_column_val(artists_rdd, COL_COUNTRY))\n",
    "    save_as_tsv(sorted_by_country, 'result_3.tsv')\n",
    "task_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_4():\n",
    "    COL_ARTIST_ID = 1\n",
    "    sorted_by_albums = sort_key_val(count_column_val(albums_rdd, COL_ARTIST_ID), key_is_num=True)\n",
    "    save_as_tsv(sorted_by_albums, 'result_4.tsv')\n",
    "task_4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_5():\n",
    "    COL_GENRE, COL_NUM_SALES = 3, 6\n",
    "    genre_sales = lambda x: (x[COL_GENRE], x[COL_NUM_SALES])\n",
    "    add = lambda a, b: int(a) + int(b)\n",
    "    \n",
    "    sales_per_genre = albums_rdd.map(genre_sales).reduceByKey(add).collectAsMap()\n",
    "    sorted_sales = sort_key_val(sales_per_genre)\n",
    "    save_as_tsv(sorted_sales, 'result_5.tsv')\n",
    "task_5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_6():\n",
    "    ID = 0\n",
    "    ROLLING_STONE, MTV, MUSIC_MANIAC = 7, 8, 9\n",
    "    get_critics = lambda x: (x[ID], (\n",
    "        float(x[ROLLING_STONE]) + float(x[MTV]) + float(x[MUSIC_MANIAC]))/3)\n",
    "    avg_critic = albums_rdd.map(get_critics).takeOrdered(10, lambda (_id, avg): -avg)\n",
    "    save_as_tsv(avg_critic, 'result_6.tsv')\n",
    "task_6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_7():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
